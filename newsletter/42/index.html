<!DOCTYPE html>

<html lang="de">
<head>
<meta charset="utf-8"/>
<title>Homepage Tobias Fr√§nzel</title>
<meta content="" name="description">
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<link href="../../styles/styles.css" rel="stylesheet" type="text/css"/>
<link href="../../styles/newsletter_styles.css" rel="stylesheet" type="text/css"/>
<link href="../../img/favicon.png" rel="icon" type="image/png"/>
<!-- Mailchimp signup styles -->
<link href="//cdn-images.mailchimp.com/embedcode/classic-10_7.css" rel="stylesheet" type="text/css"/>
<style type="text/css">
      #mc_embed_signup form{padding:0;margin-top:2em;}
    	/* Add your own Mailchimp form style overrides in your site stylesheet or in this style block.
    	   We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
    </style>
</meta></head>
<body>
<nav class="menu-main">
<ul>
<li><a href="../../index.html">Tobias Fr√§nzel</a></li>
<li><a href="../../newsletter.html">Newsletter</a></li>
<li><a href="../../projekte.html">Projekte</a></li>
<li><a href="../../kontakt.html">Kontakt</a></li>
</ul>
</nav>
<hr class="divider"/>
<div id="container-main">
<h1>KI News #42</h1><span>
                        
                            Hallo und herzlich willkommen zur zweiundvierzigsten Ausgabe von KI News. Diesmal mit Texten, aus denen 3D-Modelle entstehen, einem neuen effizienten Audio-Codec, einem Sprachmodell, das wissenschaftliche Fragen beantworten k√∂nnen soll und noch mehr.<p>
Viel Spa√ü beim Lesen!
                        </p></span><h2 id="2">Inhalt</h2><span><ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;"><a href="#3">Text-zu-3D-Modelle von Nvidia und Open AI</a></li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;"><a href="#4">Audio-Codec basierend auf neuronalen Netzen</a></li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;"><a href="#5">Galactica - Sprachmodelle als Schnittstelle zur Wissenschaft?</a></li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;"><a href="#6">Zusammengefasst</a>
	<ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Metas neues Modell f√ºr Text, Audio und Bilder: data2vec 2.0</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Sprachmodell sagt Proteinstrukturen voraus</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Bessere Vorschl√§ge f√ºr Programmierer durch KI</li>
</ul>
</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;"><a href="#7">Au√üerdem</a></li>
</ul></span><h2 id="3">Text-zu-3D-Modelle von Nvidia und Open AI</h2><span><p>
Nvidias neues Modell hei√üt <em>Magic3D</em>. Die Forscher:innen verfolgen dabei einen zweistufigen Ansatz: Zuerst lassen sie eine 3D-Darstellung mit geringer Qualit√§t erzeugen und verbessern dann im zweiten Schritt die Aufl√∂sung.</p><p></p><p>
F√ºr den ersten Schritt generiert ein <a href="http://tobiasfraenzel.de/newsletter/40/#2" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Diffusion Modell</a> ein Bild mit geringer Aufl√∂sung, das zum Text passt. Ein anderes neuronales Netz erzeugt dann aus diesem Bild die erste 3D-Darstellung.</p><p>
Im zweiten Schritt erh√∂ht ein weiteres Diffusion Modell (genauer: <a href="https://de.wikipedia.org/wiki/Stable_Diffusion" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank"><em>Stable Diffusion</em></a>) die Aufl√∂sung des Bildes aus Schritt eins. Basierend darauf wird auch die Aufl√∂sung der 3D-Darstellung entsprechend erh√∂ht.</p><p></p><p>
Um schneller zu sein als das <a href="http://tobiasfraenzel.de/newsletter/40/#4" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank"><em>DreamFusion</em></a> Modell, das im September ver√∂ffentlicht wurde, benutzt <em>Magic3D</em> eine <a href="https://nvlabs.github.io/instant-ngp/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Optimierung</a> f√ºr die Umwandlung des Bildes in 3D. Dadurch ist <em>Magic3D</em> ungef√§hr doppelt so schnell wie <em>DreamFusion</em> (40 min statt 90 min).</p><p></p><p><em>Kurz gesagt</em>:</p><p>
1. Text -&gt; Bild mit geringer Aufl√∂sung -&gt; 3D-Darstellung</p><p>
2. Aufl√∂sung des Bildes erh√∂hen -&gt; Aufl√∂sung der 3D-Darstellung erh√∂hen</p><p></p><p>
Die Forscher:innen von OpenAI nennen ihr Modell <em>Point-E</em>. Sie benutzen ebenfalls einen zweistufigen Prozess, aber geben der Geschwindigkeit noch h√∂here Priorit√§t gegen√ºber der Qualit√§t der Ergebnisse.</p><p></p><p>
Auch bei <em>Point-E</em> gibt es im ersten Schritt ein Diffusion Modell (eine Variante des <a href="http://tobiasfraenzel.de/newsletter/22/#4" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank"><em>GLIDE</em></a> Modells), das aus dem Text ein Bild generiert.</p><p></p><p>
Der Unterschied zu <em>Magic3D</em> liegt in dem was darauf folgt. In Schritt zwei erzeugt n√§mlich ein weiteres Diffusion Modell aus dem Bild eine 3D-Punktewolke mit 1.000 Punkten. Darauf folgt nochmal ein Diffusion Modell, das die Aufl√∂sung auf 4.000 Punkte erh√∂ht.</p><p></p><p>
Mit diesem Ansatz schaffen es die Forscher:innen, eine 3D-Darstellung in nur 1-2 Minuten generieren zu lassen, wenn auch mit geringerer Qualit√§t als <em>DreamFusion</em> oder <em>Magic3D</em>.</p><p></p><p><em>Kurz gesagt</em>:</p><p>
1. Text -&gt; Bild</p><p>
2. Bild -&gt; 3D-Punktewolke mit 1.000 Punkten -&gt; 3D-Punktewolke mit 4.000 Punkten
<ul>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Webseite von Magic3D: <a href="https://deepimagination.cc/Magic3D/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://deepimagination.cc/Magic3D/</a></li>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Ver√∂ffentlichung der Forscher:innen zu Magic3D: <a href="https://arxiv.org/abs/2211.10440" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://arxiv.org/abs/2211.10440</a></li>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Code von Point-E: <a href="https://github.com/openai/point-e" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://github.com/openai/point-e</a></li>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Ver√∂ffentlichung der Forscher:innen zu Point-E: <a href="https://arxiv.org/abs/2212.08751" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://arxiv.org/abs/2212.08751</a></li>
</ul></p></span><h2 id="4">Audio-Codec basierend auf neuronalen Netzen</h2><span><p>
Meta hat ein Verfahren namens <em>Encodec</em> entwickelt, das, mithilfe von neuronalen Netzen, Audio-Dateien auf ein Zehntel der Gr√∂√üe von Mp3 komprimieren kann. Eine Datei braucht bei vergleichbarer Qualit√§t nur noch 6 Kilobyte pro Sekunde statt 64 kb bei Mp3.</p><p></p><p>
Um Dateien zu komprimieren ben√∂tigt Encodec zwei Teile: ein neuronales Netz mit <a href="https://de.wikipedia.org/wiki/Convolutional_Neural_Network" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">CNN-Architektur</a>, das die Informationen aus der Original-Datei verarbeitet, sowie einen weiteren Teil, der das Ergebnis davon mithilfe von <a href="https://de.wikipedia.org/wiki/Vektorquantisierung" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Vektorquantisierung</a> komprimiert.</p><p></p><p>
Beim Training sind noch weitere Komponenten n√∂tig.</p><p>
Das sind zum einen ein weiteres CNN, das die komprimierten Daten wieder in eine Audiodatei umwandelt, und zum anderen ein "Diskriminator". Das ist ein neuronales Netz, das lernt, die verarbeitete Datei vom Original zu unterscheiden. Mit diesem Feedback kann das erste CNN lernen, eine Komprimierung zu finden, bei der das Ergebnis dem Original m√∂glichst √§hnlich ist.</p><p>
Da der Diskriminator nicht wissen kann, wie etwas f√ºr Menschen klingt, benutzen die Forscher:innen die <a href="https://de.wikipedia.org/wiki/Spektrogramm" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Spektrogramme</a> der Dateien als Hilfsmittel, um den Klang darzustellen.</p><p></p><p>
Ein Vorteil dieses Ansatzes im Vergleich zu vielen anderen aktuellen ML Modellen ist, dass er relativ ressourceneffizient ist. Man braucht keine Hochleistungs-Grafikkarte um <em>Encodec</em> auszuf√ºhren, sondern es funktioniert auf einem einzelnen CPU-Kern.</p><p></p><p><em>Kurz gesagt</em>:</p><p>
Ausf√ºhrung: Original-Audio -&gt; CNN zur Komprimierung -&gt; Vektorquantisierung -&gt; komprimierte Daten</p><p>
Training: Original-Audio -&gt; CNN zur Komprimierung -&gt; Vektorquantisierung -&gt; komprimierte Daten -&gt; CNN zur R√ºckumwandlung in Audio -&gt; Diskriminator vergleicht mit Original und gibt Feedback an das CNN zur Komprimierung
<ul>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Blogeintrag von Meta AI: <a href="https://ai.facebook.com/blog/ai-powered-audio-compression-technique/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://ai.facebook.com/blog/ai-powered-audio-compression-technique/</a></li>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Code auf Github: <a href="https://github.com/facebookresearch/encodec" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://github.com/facebookresearch/encodec</a></li>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Ver√∂ffentlichung der Forscher:innen: <a href="https://arxiv.org/abs/2210.13438" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://arxiv.org/abs/2210.13438</a></li>
</ul></p></span><h2 id="5">Galactica - Sprachmodelle als Schnittstelle zur Wissenschaft?</h2><span><p>
Forscher:innen von Meta haben ein Sprachmodell namens <em>Galactica</em> entwickelt, das auf "high-quality" Daten trainiert wurde. Dazu geh√∂ren zum Beispiel wissenschaftliche Ver√∂ffentlichungen, Lehrb√ºcher, Vorlesungsnotizen und Enzyklop√§dien.</p><p></p><p>
Interessant bei Galactica ist, dass das Modell auch in einigen Testaufgaben, die nichts mit Wissenschaft zu tun haben, besser war als andere, zum Teil deutlich gr√∂√üere, Sprachmodelle. Das k√∂nnte darauf hindeuten, dass die Qualit√§t der Trainingsdaten f√ºr Sprachmodelle eine wichtigere Rolle spielt als bisher angenommen.</p><p></p><p>
F√ºr mehr Aufmerksamkeit hat aber etwas anderes gesorgt. Meta hat n√§mlich nach Protesten die Demo-Version des Modells nach nur drei Tagen wieder von der Webseite genommen.</p><p></p><p>
Der gr√∂√üte Kritikpunkt dabei war, dass Meta den Anschein erweckt hat, als k√∂nnte das Modell eine Art Schnittstelle f√ºr Wissen sein: Laut der Webseite: "<em>Sie k√∂nnen damit die Literatur erforschen, wissenschaftliche Fragen stellen, wissenschaftlichen Code schreiben und vieles mehr</em>".</p><p></p><p>
Das klingt erstmal gut. Ein Modell, das auf wissenschaftlichen Arbeiten trainiert wurde, gibt auch wissenschaftliche Antworten, oder?</p><p></p><p>
Leider nicht.</p><p>
Sprachmodelle wie Galactica lernen kein "Wissen", sondern nur die statistischen Eigenschaften von Texten. Daher wirken ihre Ausgaben zwar zum Teil sehr intelligent, sie sind aber einfach nur eine statistisch wahrscheinliche Fortsetzung eines Textes.</p><p></p><p>
Und das ist auch Meta bewusst, denn im Abschnitt "<em>Limitations</em>" schreiben sie unter anderem <em>"Es gibt keine Garantien f√ºr wahrheitsgem√§√üe oder zuverl√§ssige Ergebnisse von Sprachmodellen</em>" und "<em>Sprachmodelle sind oft selbstbewusst, aber falsch. Einige der von Galactica generierten Texte k√∂nnen sehr authentisch und selbstbewusst erscheinen, aber in wichtigen Punkten subtil falsch sein</em>".</p><p></p><p>
Oder kurz gesagt: man kann sich nicht darauf verlassen, dass die Antworten stimmen, auch wenn sie richtig wirken.</p><p></p><p>
Das steht nat√ºrlich im Konflikt mit dem Anspruch von Meta, dass das Modell als eine Art Schnittstelle zu wissenschaftlichen Erkenntnissen genutzt werden kann.</p><p></p><p>
Und das ist auch vielen Leuten aufgefallen, die das Modell ausprobiert haben.</p><p>
Dazu geh√∂rt unter anderem Michael Black, der Direktor des Max-Planck-Institutes f√ºr Intelligente Systeme in T√ºbingen, der seine Versuche mit Galactica auf Twitter ver√∂ffentlich hat und es als "<em>potenziell verzerrend und gef√§hrlich f√ºr die Wissenschaft</em>" beschreibt: <a href="https://twitter.com/Michael_J_Black/status/1593133722316189696" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://twitter.com/Michael_J_Black/status/1593133722316189696</a><ul>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Webseite von Galactica: <a href="https://galactica.org/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://galactica.org/</a></li>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Ver√∂ffentlichung der Forscher:innen (PDF): <a href="https://galactica.org/static/paper.pdf" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://galactica.org/static/paper.pdf</a></li>
</ul></p></span><h2 id="6">Zusammengefasst</h2><span><div class="source">¬†</div><em><strong><span style="font-size:18px">Metas neues Modell f√ºr Text, Audio und Bilder: data2vec 2.0</span></strong></em><div class="source">
<div class="source">Ungef√§hr vor einem Jahr, am 20. Januar 2022, wurde die erste Version von <a href="http://tobiasfraenzel.de/newsletter/25/#2" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank"><em>data2vec</em></a> ver√∂ffentlicht. Die grunds√§tzliche Funktionsweise ist auch in Version zwei noch die gleiche wie beim Original: F√ºr jede Art von Daten (Text, Audio, Bilder) wird ein separates Modell trainiert.<br/>
Diese Modelle nennen die Forscher:innen "Teacher"-Modelle. Dann trainieren sie das eigentliche <em>data2vec</em> Modell darauf, wenn es eine bestimmte Art von Eingabedaten bekommt, den internen Zustand des entsprechenden Teacher-Modells vorherzusagen.<br/>
So kann es alle drei Arten von Daten verarbeiten.<br/>
Durch verschiedene Optimierungen in der Art, wie die Daten im Training verarbeitet werden, sowie ein neuronales Netz mit einer anderen Architektur in einem Teil von <em>data2vec 2.0</em>, konnte die Geschwindigkeit im Vergleich zur ersten Version deutlich gesteigert werden.

<ul>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Blogeintrag von Meta AI zu data2vec 2.0: <a href="https://ai.facebook.com/blog/ai-self-supervised-learning-data2vec/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://ai.facebook.com/blog/ai-self-supervised-learning-data2vec/</a></li>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Ver√∂ffentlichung der Forscher:innen zu data2vec 2.0: <a href="https://ai.facebook.com/research/publications/efficient-self-supervised-learning-with-contextualized-target-representations-for-vision-speech-and-language" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://ai.facebook.com/research/publications/efficient-self-supervised-learning-with-contextualized-target-representations-for-vision-speech-and-language</a></li>
</ul>
<div class="source">¬†</div>
<div class="source"><strong><em><span style="font-size:18px">Sprachmodell sagt Proteinstrukturen voraus</span></em></strong><br/>
Das <a href="https://www.deepmind.com/research/highlighted-research/alphafold" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank"><em>AlphaFold</em></a>-Modell von DeepMind (geh√∂rt zu Google) hat Ende 2020 mit der genauen Vorhersage von Proteinstrukturen f√ºr Aufsehen gesorgt und die Forscher:innen haben inzwischen in einer Datenbank die Strukturen von 200 Millionen Proteinen <a href="https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">ver√∂ffentlicht</a>.<br/>
Jetzt haben Forscher:innen von Meta nachgezogen und ein Modell namens <em>ESMFold</em> entwickelt. Dabei handelt es sich um ein Sprachmodell mit 15 Milliarden Parametern.<br/>
Aminos√§ure-Sequenzen von Proteinen lassen sich auch als Buchstaben darstellen, so dass ein Sprachmodell damit arbeiten kann. Deshalb wurde das Modell mit Daten in dieser Darstellung trainiert.<br/>
Die Ergebnisse sind nicht so genau wie die von <em>AlphaFold</em>, aber daf√ºr ist die Vorhersage deutlich schneller (je nach L√§nge der Proteinsequenz 6x bis 60x schneller).<br/>
Mithilfe von <em>ESMFold</em> haben die Forscher:innen 617 Millionen Strukturen von Proteinen vorhergesagt, davon werden 225 Millionen als hohe Qualit√§t eingesch√§tzt.

<ul>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Artikel bei Nature: <a href="https://www.nature.com/articles/d41586-022-03539-1" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://www.nature.com/articles/d41586-022-03539-1</a></li>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Ver√∂ffentlichung der Forscher:innen: <a href="https://www.biorxiv.org/content/10.1101/2022.07.20.500902v2" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://www.biorxiv.org/content/10.1101/2022.07.20.500902v2</a></li>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Atlas der vorhergesagten Proteinstrukturen: <a href="https://esmatlas.com/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://esmatlas.com/</a></li>
</ul>
<div class="source">¬†</div>
<div class="source">
<div class="source"><strong><em><span style="font-size:18px">Bessere Vorschl√§ge f√ºr Programmierer durch KI</span></em></strong><br/>
<a href="https://de.wikipedia.org/wiki/Integrierte_Entwicklungsumgebung" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Integrated Development Environments</a> (IDEs) sind die Programme, mit denen Programmierer:innen programmieren. Viele IDEs analysieren dabei den Code, der gerade bearbeitet wird, um Tipps und Hinweise zu geben.<br/>
Forscher:innen von Microsoft, Uber, Apple und der <a href="https://www.wisc.edu/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Universit√§t von Wisconsin-Madison</a> haben ein Modell namens <em>Overwatch</em> entwickelt, das diese Vorschl√§ge verbessern soll. Daf√ºr bezieht <em>Overwatch</em> nicht nur den aktuellen Code mit ein, an dem jemand arbeitet, sondern auch die zuletzt gemachten √Ñnderungen. Damit versucht es die √Ñnderungen vorherzusagen, die wahrscheinlich als n√§chstes gemacht werden, um daf√ºr Hilfe anzubieten.

<ul>
<li class="source" style='mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;list-style: "\1F4D6  ";'>Ver√∂ffentlichung der Forscher:innen: <a href="https://arxiv.org/abs/2207.12456" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">https://arxiv.org/abs/2207.12456</a></li>
</ul>
</div>
</div>
</div>
</div>
</div></span><h2 id="7">Au√üerdem</h2><span><ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Atom-Manipulation durch Reinforcement Learning: üìñ <a href="https://www.nature.com/articles/s41467-022-35149-w" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Ver√∂ffentlichung der Forscher:innen bei Nature</a><br/>
	¬†</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Microsoft, Github und Open AI werden wegen Github Copilot verklagt:
	<ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">üìñ <a href="https://githubcopilotlitigation.com/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Webseite der Anwaltskanzlei zur Klage</a></li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">¬†üìñ <a href="https://www.bleepingcomputer.com/news/security/microsoft-sued-for-open-source-piracy-through-github-copilot/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Artikel bei Bleepingcomputer</a><br/>
		¬†</li>
</ul>
</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Mit <em>Hey Github</em> programmieren ohne zu tippen: üìñ <a href="https://githubnext.com/projects/hey-github" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Anmeldeseite f√ºr die Vorschauversion</a><br/>
	¬†</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">OpenAI hat Version 2 des Whisper Modells zur Spracherkennung ver√∂ffentlicht: üìñ <a href="https://github.com/openai/whisper/commit/4179ed2475cc84cba66868b516232ef1b74dacdf" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Code auf Github</a><br/>
	¬†</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Es gibt ein neues open source Sprachmodell f√ºr Klassifikation:¬† üìñ <a href="https://www.together.xyz/blog/releasing-v1-of-gpt-jt-powered-by-open-source-ai" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Blogeintrag von Together</a><br/>
	¬†</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Robb Oat ist eine App f√ºr Github, die, basierend auf einer Beschreibung, selbstst√§ndig Code entsprechend √§ndern kann:¬†üìñ <a href="https://robboat.com/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">robboat.com</a><br/>
	¬†</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Eine Github Action, die, mithilfe von GPT-3, automatisch eine Zusammenfassung einer Code√§nderung schreiben kann:¬†üìñ <a href="https://github.com/KanHarI/gpt-commit-summarizer" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Code auf Github</a></li>
</ul></span>
<p id="bottom-nav-container"><a href="../41">¬´ Vorherige</a><a class="hidden" href="">N√§chste ¬ª</a></p>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup">
<form action="https://tobiasfraenzel.us7.list-manage.com/subscribe/post?u=6a2f372a93d527ee449b8e785&amp;id=9d690dbb78" class="validate" id="mc-embedded-subscribe-form" method="post" name="mc-embedded-subscribe-form" novalidate="" target="_blank">
<div id="mc_embed_signup_scroll">
<p>Hier abonnieren und keine Ausgabe mehr verpassen:</p>
<!--<div class="indicates-required"><span class="asterisk">*</span> Pflichtfeld</div>-->
<div class="mc-field-group">
<label for="mce-EMAIL">E-Mail Adresse:<!--<span class="asterisk">*</span>--></label>
<input class="required email" id="mce-EMAIL" name="EMAIL" type="email" value=""/>
</div>
<!--<div class="mc-field-group">
                      <label for="mce-FNAME">Name</label>
                          <input type="text" value="" name="FNAME" class="" id="mce-FNAME">
                  </div>-->
<div class="clear" id="mce-responses">
<div class="response" id="mce-error-response" style="display:none"></div>
<div class="response" id="mce-success-response" style="display:none"></div>
</div> <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
<div aria-hidden="true" style="position: absolute; left: -5000px;"><input name="b_6a2f372a93d527ee449b8e785_9d690dbb78" tabindex="-1" type="text" value=""/></div>
<div class="clear"><input class="button" id="mc-embedded-subscribe" name="subscribe" type="submit" value="Anmelden"/></div>
</div>
</form>
</div>
</div>
</body>
<!-- Matomo -->
<script type="text/javascript">
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
      var u="//tobiasfraenzel.de/misc/piwik/";
      _paq.push(['setTrackerUrl', u+'matomo.php']);
      _paq.push(['setSiteId', '1']);
      var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
      g.type='text/javascript'; g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
    })();
  </script>
<!-- End Matomo Code -->
</html>
