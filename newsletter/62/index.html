<!DOCTYPE html>

<html lang="de">
<head>
<meta charset="utf-8"/>
<title>Homepage Tobias FrÃ¤nzel</title>
<meta content="" name="description">
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<link href="../../styles/styles.css" rel="stylesheet" type="text/css"/>
<link href="../../styles/newsletter_styles.css" rel="stylesheet" type="text/css"/>
<link href="../../img/favicon.png" rel="icon" type="image/png"/>
<!-- Mailchimp signup styles -->
<link href="//cdn-images.mailchimp.com/embedcode/classic-10_7.css" rel="stylesheet" type="text/css"/>
<style type="text/css">
      #mc_embed_signup form{padding:0;margin-top:2em;}
    	/* Add your own Mailchimp form style overrides in your site stylesheet or in this style block.
    	   We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
    </style>
</meta></head>
<body>
<nav class="menu-main">
<ul>
<li><a href="../../index.html">Tobias FrÃ¤nzel</a></li>
<li><a href="../../newsletter.html">Newsletter</a></li>
<li><a href="../../projekte.html">Projekte</a></li>
<li><a href="../../kontakt.html">Kontakt</a></li>
</ul>
</nav>
<hr class="divider"/>
<div id="container-main">
<h1>KI News #62</h1><span>
                        
                            Hallo und herzlich willkommen zur zweiundsechzigsten Ausgabe von KI News. Heute geht es um die DeepSeek-Ãœberraschung, was da eigentlich passiert ist und was darauf folgen kÃ¶nnte.<p>
Viel SpaÃŸ beim Lesen!
                        </p></span><h2 id="2">Inhalt</h2><span><p style="margin: 10px 0;padding: 0;mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;font-family: Helvetica;font-size: 16px;line-height: 150%;text-align: left;"></p><ul>
<li><a href="#3">Was ist eigentlich passiert?</a></li>
<li><a href="#4">Was ist der Unterschied zwischen einem Sprachmodell und einem Reasoning-Modell?</a></li>
<li><a href="#5">Warum die heftige Reaktion?</a></li>
<li><a href="#6">Gab es einen Durchbruch beim Training?</a></li>
<li><a href="#7">Rechnen sich die groÃŸen KI Investitionen jetzt noch?</a></li>
<li><a href="#8">Haben die USA die TechnologiefÃ¼hrerschaft verloren?</a></li>
<li><a href="#9">Fazit und Quellen</a></li>
</ul></span><h2 id="3">Was ist eigentlich passiert?</h2><span><p style="margin: 10px 0;padding: 0;mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;font-family: Helvetica;font-size: 16px;line-height: 150%;text-align: left;"><br/>
Das chinesische Startup DeepSeek hat seit Ende Dezember zwei neue Modelle verÃ¶ffentlicht, die fÃ¼r viel Aufsehen gesorgt haben:</p><ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">ein Sprachmodell namens "V3"</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">ein "Reasoning"-Modell namens "R1"</li>
</ul><p style="margin: 10px 0;padding: 0;mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;font-family: Helvetica;font-size: 16px;line-height: 150%;text-align: left;">Zusammen mit den Modellen hat DeepSeek auch viele Informationen zu Training und Entwicklung verÃ¶ffentlicht. Zudem sind die Modelle als open-source verfÃ¼gbar, so dass im Prinzip jeder sie herunterladen und selbst ausfÃ¼hren kann.<br/>
<br/>
Vor allem das Reasoning-Modell R1 Modell hat kurz nach seiner VerÃ¶ffentlichung im Januar einige Aufmerksamkeit bekommen und in der Reaktion unter anderem zu einem Kurseinbruch der Nvidia Aktie gefÃ¼hrt</p></span><h2 id="4">Was ist der Unterschied zwischen einem Sprachmodell und einem Reasoning-Modell?</h2><span><p style="margin: 10px 0;padding: 0;mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;font-family: Helvetica;font-size: 16px;line-height: 150%;text-align: left;"><br/>
<br/>
Einfach gesagt soll ein Sprachmodell die menschliche Sprache abbilden und somit vorhersagen kÃ¶nnen. Deshalb werden Sprachmodelle mit groÃŸen Mengen von Texten trainiert, um so die statistischen Wahrscheinlichkeiten von WÃ¶rtern (bzw. Tokens) daraus zu lernen.<br/>
Bekannte Beispiele sind die "GPT" Modelle von OpenAI, die angefangene Texte vervollstÃ¤ndigen kÃ¶nnen.<br/>
<br/>
Ein Reasoning-Modell (wie die "o" Modelle von OpenAI) dagegen soll menschliche Logik abbilden und eigene Schlussfolgerungen ziehen kÃ¶nnen.<br/>
Da sich logische Argumente in Sprache ausdrÃ¼cken lassen, sind aktuelle Reasoning-Modelle einfach weiterentwickelte Sprachmodelle.<br/>
<br/>
Der Unterschied ist, dass diese nicht nur eine einfache Text-Fortsetzung generieren und an den/die Nutzer:in zurÃ¼ck geben, wie es ein Sprachmodell macht.<br/>
Stattdessen werden Reasoning-Modelle dazu gebracht, eine Art Zwischentext zu generieren, in dem sie verschiedene logische Schritte betrachten und auch den bereits generierten Text immer wieder Ã¼berprÃ¼fen.<br/>
<br/>
Basierend auf diesem Zwischentext, der jetzt verschiedene Schritte, Argumente und ÃœberprÃ¼fungen enthalten sollte, generiert das Modell dann erst die abschlieÃŸende Antwort, die dem/der Nutzer:in gezeigt wird.</p></span><h2 id="5">Warum die heftige Reaktion?</h2><span><p>
In der VerÃ¶ffentlichung zu R1 schreibt DeepSeek, dass das Modell in verschiedenen Tests Ã¤hnlich gut abschneidet wie das o1 Modell von OpenAI.</p><p>
Angesichts der US-Sanktionen, die den Export der leistungsfÃ¤higsten Nvidia-Chips (GPUs) nach China beschrÃ¤nken, wurde das als Hinweis gesehen, dass DeepSeek ein Durchbruch gelungen sein kÃ¶nnte, der das Training von leistungsstarken Modellen sehr viel effizienter macht.</p><p></p><p>
Dazu kommt, dass das R1 Modell auf dem V3 Modell basiert. Zu V3 schreibt DeepSeek, dass das Modell auf "nur" 2.048 Nvidia H800 GPUs trainiert wurde. Bei einem angenommenen Mietpreis von 2$ pro Stunde fÃ¼r eine H800 GPU habe das Training von V3 ca 5,6 Millionen US-Dollar gekostet, was fÃ¼r aktuelle KI-Modelle sehr wenig ist.</p><p></p><p>
Daher entstand der Eindruck, DeepSeek habeÂ fÃ¼r $5,6 Millionen ein Modell entwickelt, das Ã¤hnlich leistungsfÃ¤hig ist wie o1 und dabei mutmaÃŸlich mehrere GrÃ¶ÃŸenordnungen weniger kostet.</p><p></p><p>
Diese Annahme ist allerdings nicht ganz richtig, denn der Betrag deckt nur das eigentliche Training des V3 Sprachmodells ab, aber:
<ol>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Schon vor dem Training ist sehr viel Vorbereitungsaufwand notwendig</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Das R1 Modell ist eine Weiterentwicklung von V3, in die vermutlich viel Arbeit geflossen ist</li>
</ol>
Man kann also davon ausgehen, dass die gesamte Entwicklung von R1 deutlich mehr gekostet hat als die genannten $5,6 Millionen, aber wahrscheinlich trotzdem deutlich weniger als dieÂ Entwicklung anderer fÃ¼hrender KI-Modelle der US-amerikanischen Konkurrenz.</p><p></p><p>
Zum Vergleich: Meta hat das Llama 3 Modell letztes Jahr auf zwei Clustern mit jeweils 24.000 GPUs trainiert und angekÃ¼ndigt, bis Ende 2024 insgesamt 350.000 Nvidia H100 GPUs zu kaufen.</p><p>
GegenÃ¼ber diesen Milliarden-Investitionen, die genauso auch OpenAI und andere US-Unternehmen getÃ¤tigt haben, scheinen die Kosten von DeepSeek extrem gering.</p><p></p><p>
Darauf, dass DeepSeek tatsÃ¤chlich weniger Kosten fÃ¼r die Entwicklung der Modelle hatte, weisen die Preise hin, die DeepSeek fÃ¼r die Benutzung der eigenen Modelle verlangt - denn die sind sehr viel geringer als die Preise der Konkurrenz.</p><p></p><p>
Wenn es einem chinesischen Startup also gelingen kann, innerhalb kurzer Zeit und zu einem Bruchteil der Kosten ein KI-Modell zu entwickeln, das Ã¤hnlich gute Ergebnisse liefert wie die aktuell fÃ¼hrenden Modelle, dann wirft das einige Fragen auf:
<ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Ist den chinesischen Forscher:innen ein Durchbruch gelungen, durch den in Zukunft beim Training von KI-Modellen deutlich weniger Rechenleistung nÃ¶tig sein wird?<br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">KÃ¶nnen sich die Milliarden-Investitionen in neue Rechenzentren und Supercomputer jemals rechnen, wenn die chinesische Konkurrenz den gleichen Service so viel gÃ¼nstiger anbieten kann?<br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Haben die USA ihre TechnologiefÃ¼hrerschaft bei KI verloren?</li>
</ul></p></span><h2 id="6">Gab es einen Durchbruch beim Training?</h2><span><p>
Die Forscher:innen von DeepSeek beschreiben mehrere Innovationen, die das Training von V3 effizienter gemacht haben:
<ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Es ist ein "Mixture of Experts" Modell. Das bedeutet, dass immer nur ein kleiner Teil des Modells tatsÃ¤chlich benutzt wird. Dadurch benÃ¶tigt es weniger Rechenleistung. Nach diesem Prinzip arbeiten auch schon andere Modelle, z.B. Mixtral und mutmaÃŸlich auch GPT-4, DeepSeek hat es aber noch weiter optimiert.<br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Weitere Verbesserungen sind die sogenannten "multi-head latent attention" und "multi-token prediction". Dadurch wird die Datenverarbeitung bei der Berechnung einer Vorhersage effizienter.<br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Einige Berechnungen werden auÃŸerdem mit geringerer PrÃ¤zision durchgefÃ¼hrt, was ebenfalls dazu fÃ¼hrt, dass weniger Rechenleistung benÃ¶tigt wird.</li>
</ul>
Auch die Weiterentwicklung des V3 Sprachmodells zum R1 Reasoning-Modell hat DeepSeek auf eine relativ effiziente Weise geschafft, denn sie haben stark auf sogenanntes "<a href="https://de.wikipedia.org/wiki/Best%C3%A4rkendes_Lernen" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Reinforcement Learning</a>" gesetzt.</p><p>
Das hat den Vorteil, dass es vollstÃ¤ndig automatisch passieren kann, ohne dass das Modell auf menschliche (und damit langsame und teure) RÃ¼ckmeldungen angewiesen ist.</p><p></p><p>
Beim Reinforcement Learning werden die Antworten des Modells automatisiert geprÃ¼ft und bewertet, so dass das Modell lernen kann, was eine gute Antwort ist.</p><p></p><p>
Die Kriterien dafÃ¼r hat DeepSeek sehr einfach gewÃ¤hlt, wodurch sie wiederum auch einfach (und damit ressourcenschonend) Ã¼berprÃ¼fbar waren:
<ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Wurde ein gekennzeichneter Zwischentext generiert?</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Ist die Antwort richtig? (z.B. bei Rechen- oder Programmieraufgaben ist das fÃ¼r einen Computer relativ leicht zu Ã¼berprÃ¼fen)</li>
</ul>
Beides sind Kriterien, die sich mit einfachen Mitteln, wenig Aufwand und somit kostengÃ¼nstig und schnell prÃ¼fen lassen.</p><p></p><p>
Das ist nicht der eine groÃŸe Durchbruch, aber mehrere kleine Verbesserungen zusammen genommen kÃ¶nnen eben auch einen groÃŸen Unterschied machen.
                        </p></span><h2 id="7">Rechnen sich die groÃŸen KI Investitionen jetzt noch?</h2><span><p>
Erst vor kurzem haben OpenAI und andere im Rahmen eines Projekts namens "Stargate" angekÃ¼ndigt, in den nÃ¤chsten Jahren viele Milliarden US-Dollar in KI-Infrastruktur zu investieren.</p><p>
Auch der franzÃ¶sische PrÃ¤sident Macron hat erst vor kurzem Investitionen von mehr als 100 Milliarden Euro angekÃ¼ndigt, die EU-Kommission sogar von 200 Milliarden Euro.</p><p></p><p>
Lohnt sich das angesichts der neuen Entwicklungen Ã¼berhaupt noch?</p><p></p><p>
Diese Frage ist schwierig zu beantworten, weil sie von so vielen Faktoren abhÃ¤ngig ist.
<ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">DeepSeek hat seine Verbesserungen verÃ¶ffentlicht - wie einfach kÃ¶nnen sie jetzt von anderen Unternehmen in deren jeweilige KI-Architekturen Ã¼bernommen werden?<br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">WÃ¤ren die KI-Modelle von DeepSeek noch besser, wenn sie zusÃ¤tzliche Rechenleistung zur VerfÃ¼gung gehabt hÃ¤tten?<br/>
	KÃ¶nnte also zum Beispiel Meta die Verbesserungen einfach fÃ¼r das nÃ¤chste Modell ihrer Llama-Reihe Ã¼bernehmen, es wie bisher auf einem der riesigen GPU-Cluster trainieren, und eine noch viel bessere Leistung bekommen als bisher?<br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">KÃ¶nnen die Modelle bessere Antworten liefern, wenn sie bei ihren Vorhersagen mehr Rechenleistung zur VerfÃ¼gung haben? KÃ¶nnte man die groÃŸen Rechenzentren also fÃ¼r den Betrieb der Modelle brauchen, falls sie fÃ¼r das Training nicht mehr nÃ¶tig sind?<br/>
	Es gibt Hinweise darauf, dass die Rechenleistung nicht nur beim Training eine wichtige Rolle spielt, sondern, dass Modelle auch bessere Vorhersagen machen, wenn man ihnen dabei zusÃ¤tzliche Rechenleistung gibt (sogenanntes "inference-time compute" oder "test-time compute"). Beispielsweise hat das OpenAIs o3 Modell Ende letzten Jahres beim "arcprize" Wettbewerb gezeigt.<br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Steigt die Nachfrage nach KI, wenn der Preis dafÃ¼r sinkt? Diese Vermutung hat beispielsweise der CEO von Microsoft, Satya Nadella, mit Bezug auf das <a href="https://de.wikipedia.org/wiki/Jevons-Paradoxon" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Jevons-Paradoxon</a>, geteilt.</li>
</ul></p></span><h2 id="8">Haben die USA die TechnologiefÃ¼hrerschaft verloren?</h2><span><p>
FÃ¼r diese Frage macht die VerÃ¶ffentlichung von R1, meiner Meinung nach, aus mehreren GrÃ¼nden keinen groÃŸen Unterschied.
<ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">R1 ist zwar Ã¤hnlich gut wie OpenAIs o1, aber bei OpenAI ist inzwischen schon der Nachfolger o3 im Einsatz.<br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Die Verbesserungen der Effizienz sind Weiterentwicklungen, aber keine Revolution.<br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">R1 ist auch nicht das erste chinesische Reasoning Modell, z.B. hat Alibaba schon im November 2024 ein Modell namens "QwQ-32B-Preview" verÃ¶ffentlicht.<br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Und ein Modell zu entwickeln, das Ã¤hnlich gut ist, wie eines des aktuellen MarktfÃ¼hrers, und noch dazu gÃ¼nstiger, ist zwar eine beachtliche Leistung, aber um selbst die FÃ¼hrung zu beanspruchen reicht das meiner Meinung nach noch nicht aus.</li>
</ul></p><p>
Allerdings hat DeepSeek gezeigt, dass der Vorsprung, den die neuesten Modelle vor Nachahmern haben, im Moment wohl auch von anderen schneller und gÃ¼nstiger aufholbar ist, als bisher angenommen.</p><p></p><p>
Beispielsweise sagt OpenAI, es gÃ¤be Hinweise, dass DeepSeek fÃ¼r das Training der Modelle die Ausgaben von OpenAIs Modellen verwendet hat.</p><p>
Diese Technik nennt sich "Distillation" und ist laut einem Bericht der Financial Times eine weit verbreitete Praxis, um gÃ¼nstig kleinere Modelle zu trainieren, die Ã¤hnlich leistungsfÃ¤hig sind wie deutlich grÃ¶ÃŸere, teurere Modelle.</p><p></p><p>
Um HandlungsfÃ¤higkeit zu zeigen und den eigenen Technologievorsprung zu betonen, hat OpenAI nur wenige Tage nach der VerÃ¶ffentlichung von R1 gleich zwei weiterentwickelte Varianten des eigenen Reasoning-Modells o3 zugÃ¤nglich gemacht.</p><p>
Das eine Modell namens "o3-mini" soll das bisher kostengÃ¼nstigste sein und ist sogar in der kostenlosen Variante von ChatGPT verfÃ¼gbar.</p><p>
Die zweite Variante "deep research" setzt auf die grÃ¶ÃŸere Version des o3 Modells und verbindet es mit einer Suchfunktion. So soll es selbststÃ¤ndig Antworten auf komplexe Fragen finden kÃ¶nnen.</p><p></p><p>
Die Nutzung solcher Zusatzfunktionen kÃ¶nnte es schwerer machen, ein Modell mithilfe von Distillation nachzubauen, weil z.B. die Internetsuche im Hintergrund ablÃ¤uft und man dadurch nicht mehr alle Eingabedaten sehen kann, die ein Modell nutzt, um zu einer Antwort zu kommen.
                        </p></span><h2 id="9">Fazit und Quellen</h2><span><p>
Ich denke, die Leistung des DeepSeek-Teams ist beachtlich und es ist noch nicht genau absehbar, welche Auswirkungen ihre Arbeit haben wird.</p><p></p><p>
Gerade dadurch, dass sie ihre Entwicklungen verÃ¶ffentlicht haben, im Gegensatz zu vielen anderen KI-Unternehmen, kann deren Einfluss deutlich grÃ¶ÃŸer werden.</p><p>
Denn so kÃ¶nnen die Verbesserungen von allen anderen Ã¼bernommen, angepasst und noch weiter verbessert werden.</p><p></p><p>
Ob dadurch das Training von KI-Modellen in Zukunft deutlich gÃ¼nstiger wird und die Nachfrage nach Nvidia GPUs einbricht, oder ob durch eventuell sinkende Preise die Nachfrage nach KI noch stÃ¤rker steigen wird und man somit insgesamt sogar mehr Rechenleistung braucht, kann im Moment noch niemand sicher sagen.</p><p></p><p>
Sicher scheint aktuell fast nichts zu sein, auÃŸer dass die KI-Forschung weltweit mit Hochdruck weiter vorangetrieben wird.</p><p></p><p><ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">DeepSeek R1 AnkÃ¼ndigung: ğŸ“– <a href="https://api-docs.deepseek.com/news/news250120" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">api-docs.deepseek.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">R1 auf Github:Â ğŸ“– <a href="https://github.com/deepseek-ai/DeepSeek-R1" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">github.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">R1 ausprobieren:Â ğŸ“– <a href="https://build.nvidia.com/deepseek-ai/deepseek-r1" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">build.nvidia.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Details zu den technischen Verbesserungen von DeepSeek:Â ğŸ“– <a href="https://epoch.ai/gradient-updates/how-has-deepseek-improved-the-transformer-architecture" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">epoch.ai</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Analyse der mÃ¶glichen Auswirkungen:Â ğŸ“– <a href="https://arcprize.org/blog/r1-zero-r1-results-analysis" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">arcprize.org</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">DeepSeek V3 AnkÃ¼ndigung: ğŸ“– <a href="https://api-docs.deepseek.com/news/news1226" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">api-docs.deepseek.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">V3 auf Github:Â ğŸ“– <a href="https://github.com/deepseek-ai/DeepSeek-V3" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">github.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Preisliste DeepSeek:Â ğŸ“– <a href="https://api-docs.deepseek.com/quick_start/pricing" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">api-docs.deepseek.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Preisliste OpenAI: ğŸ“– <a href="https://openai.com/api/pricing/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">openai.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Tweet von Sam Altman zu DeepSeek: ğŸ“– <a href="https://x.com/sama/status/1884066337103962416" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">x.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Reaktion auf DeepSeek am Aktienmarkt:Â ğŸ“– <a href="https://www.reuters.com/technology/chinas-deepseek-sets-off-ai-market-rout-2025-01-27/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">reuters.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Artikel Ã¼ber das Reasoning Modell von Alibaba:Â ğŸ“– <a href="https://techcrunch.com/2024/11/27/alibaba-releases-an-open-challenger-to-openais-o1-reasoning-model/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">techcrunch.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Artikel Ã¼ber das Reasoning Modell von Google: ğŸ“– <a href="https://techcrunch.com/2024/12/19/google-releases-its-own-reasoning-ai-model/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">techcrunch.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">OpenAI o3-mini AnkÃ¼ndigung: ğŸ“– <a href="https://openai.com/index/openai-o3-mini/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">openai.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">OpenAI deep research AnkÃ¼ndigung: ğŸ“– <a href="https://openai.com/index/introducing-deep-research/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">openai.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Artikel zu den Distillation-VorwÃ¼rfen:Â ğŸ“– <a href="https://www.ft.com/content/a0dfedd1-5255-4fa9-8ccc-1fe01de87ea6" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">ft.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Artikel zu Projekt Stargate:Â ğŸ“– <a href="https://www.tagesschau.de/wirtschaft/stargate-ki-trump-100.html" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">tagesschau.de</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Artikel zu Macrons AnkÃ¼ndigung von Investitionen:Â ğŸ“– <a href="https://www.manager-magazin.de/politik/europa/ki-gipfel-in-paris-frankreich-kuendigt-ki-investitionen-von-mehr-als-100-milliarden-euro-an-a-d589a4fa-8196-4ee8-9304-4896f726ae7a" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">manager-magazin.de</a>, <a href="https://techcrunch.com/2025/02/10/macron-unveils-a-112b-ai-investment-package-as-frances-answer-to-stargate/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">techcrunch.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">AnkÃ¼ndigung der EU-Kommission:Â ğŸ“– <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_25_467" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">ec.europa.eu</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Informationen zum Training von Llama 3:Â ğŸ“– <a href="https://engineering.fb.com/2024/06/12/data-infrastructure/training-large-language-models-at-scale-meta/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">engineering.fb.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Artikel Ã¼ber die GPU-PlÃ¤ne von Meta:Â ğŸ“– <a href="https://www.cnbc.com/2024/01/18/mark-zuckerberg-indicates-meta-is-spending-billions-on-nvidia-ai-chips.html" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">cnbc.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Tweet von Satya Nadella:Â ğŸ“– <a href="https://x.com/satyanadella/status/1883753899255046301" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">x.com</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">o3 test-time compute arcprize:Â ğŸ“– <a href="https://arcprize.org/blog/oai-o3-pub-breakthrough" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">arcprize.org</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">QwQ-32B-Preview AnkÃ¼ndigung:Â ğŸ“– <a href="https://qwenlm.github.io/blog/qwq-32b-preview/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">qwenlm.github.io</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Mixtral 8x22B:Â ğŸ“– <a href="https://mistral.ai/en/news/mixtral-8x22b" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">mistral.ai</a><br/>
	Â </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">GPT-4 Mixture-of-Experts-GerÃ¼cht:Â ğŸ“– <a href="https://x.com/swyx/status/1671272883379908608" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">x.com</a></li>
</ul></p></span>
<p id="bottom-nav-container"><a href="../61">Â« Vorherige</a><a class="hidden" href="">NÃ¤chste Â»</a></p>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup">
<form action="https://tobiasfraenzel.us7.list-manage.com/subscribe/post?u=6a2f372a93d527ee449b8e785&amp;id=9d690dbb78" class="validate" id="mc-embedded-subscribe-form" method="post" name="mc-embedded-subscribe-form" novalidate="" target="_blank">
<div id="mc_embed_signup_scroll">
<p>Hier abonnieren und keine Ausgabe mehr verpassen:</p>
<!--<div class="indicates-required"><span class="asterisk">*</span> Pflichtfeld</div>-->
<div class="mc-field-group">
<label for="mce-EMAIL">E-Mail Adresse:<!--<span class="asterisk">*</span>--></label>
<input class="required email" id="mce-EMAIL" name="EMAIL" type="email" value=""/>
</div>
<!--<div class="mc-field-group">
                      <label for="mce-FNAME">Name</label>
                          <input type="text" value="" name="FNAME" class="" id="mce-FNAME">
                  </div>-->
<div class="clear" id="mce-responses">
<div class="response" id="mce-error-response" style="display:none"></div>
<div class="response" id="mce-success-response" style="display:none"></div>
</div> <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
<div aria-hidden="true" style="position: absolute; left: -5000px;"><input name="b_6a2f372a93d527ee449b8e785_9d690dbb78" tabindex="-1" type="text" value=""/></div>
<div class="clear"><input class="button" id="mc-embedded-subscribe" name="subscribe" type="submit" value="Anmelden"/></div>
</div>
</form>
</div>
</div>
</body>
<!-- Matomo -->
<script type="text/javascript">
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
      var u="//tobiasfraenzel.de/misc/piwik/";
      _paq.push(['setTrackerUrl', u+'matomo.php']);
      _paq.push(['setSiteId', '1']);
      var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
      g.type='text/javascript'; g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
    })();
  </script>
<!-- End Matomo Code -->
</html>
