<!DOCTYPE html>

<html lang="de">
<head>
<meta charset="utf-8"/>
<title>Homepage Tobias Fränzel</title>
<meta content="" name="description">
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<link href="../../styles/styles.css" rel="stylesheet" type="text/css"/>
<link href="../../styles/newsletter_styles.css" rel="stylesheet" type="text/css"/>
<link href="../../img/favicon.png" rel="icon" type="image/png"/>
<!-- Mailchimp signup styles -->
<link href="//cdn-images.mailchimp.com/embedcode/classic-10_7.css" rel="stylesheet" type="text/css"/>
<style type="text/css">
      #mc_embed_signup form{padding:0;margin-top:2em;}
    	/* Add your own Mailchimp form style overrides in your site stylesheet or in this style block.
    	   We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
    </style>
</meta></head>
<body>
<nav class="menu-main">
<ul>
<li><a href="../../index.html">Tobias Fränzel</a></li>
<li><a href="../../newsletter.html">Newsletter</a></li>
<li><a href="../../projekte.html">Projekte</a></li>
<li><a href="../../kontakt.html">Kontakt</a></li>
</ul>
</nav>
<hr class="divider"/>
<div id="container-main">
<h1>KI News #62</h1><span>
                        
                            Hallo und herzlich willkommen zur zweiundsechzigsten Ausgabe von KI News. Heute geht es um die DeepSeek-Überraschung, was da eigentlich passiert ist und was darauf folgen könnte.<p>
Viel Spaß beim Lesen!
                        </p></span><h2 id="2">Inhalt</h2><span><p style="margin: 10px 0;padding: 0;mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;font-family: Helvetica;font-size: 16px;line-height: 150%;text-align: left;"></p><ul>
<li><a href="#3">Was ist eigentlich passiert?</a></li>
<li><a href="#4">Was ist der Unterschied zwischen einem Sprachmodell und einem Reasoning-Modell?</a></li>
<li><a href="#5">Warum die heftige Reaktion?</a></li>
<li><a href="#6">Gab es einen Durchbruch beim Training?</a></li>
<li><a href="#7">Rechnen sich die großen KI Investitionen jetzt noch?</a></li>
<li><a href="#8">Haben die USA die Technologieführerschaft verloren?</a></li>
<li><a href="#9">Fazit und Quellen</a></li>
</ul></span><h2 id="3">Was ist eigentlich passiert?</h2><span><p style="margin: 10px 0;padding: 0;mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;font-family: Helvetica;font-size: 16px;line-height: 150%;text-align: left;"><br/>
Das chinesische Startup DeepSeek hat seit Ende Dezember zwei neue Modelle veröffentlicht, die für viel Aufsehen gesorgt haben:</p><ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">ein Sprachmodell namens "V3"</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">ein "Reasoning"-Modell namens "R1"</li>
</ul><p style="margin: 10px 0;padding: 0;mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;font-family: Helvetica;font-size: 16px;line-height: 150%;text-align: left;">Zusammen mit den Modellen hat DeepSeek auch viele Informationen zu Training und Entwicklung veröffentlicht. Zudem sind die Modelle als open-source verfügbar, so dass im Prinzip jeder sie herunterladen und selbst ausführen kann.<br/>
<br/>
Vor allem das Reasoning-Modell R1 Modell hat kurz nach seiner Veröffentlichung im Januar einige Aufmerksamkeit bekommen und in der Reaktion unter anderem zu einem Kurseinbruch der Nvidia Aktie geführt</p></span><h2 id="4">Was ist der Unterschied zwischen einem Sprachmodell und einem Reasoning-Modell?</h2><span><p style="margin: 10px 0;padding: 0;mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;font-family: Helvetica;font-size: 16px;line-height: 150%;text-align: left;"><br/>
<br/>
Einfach gesagt soll ein Sprachmodell die menschliche Sprache abbilden und somit vorhersagen können. Deshalb werden Sprachmodelle mit großen Mengen von Texten trainiert, um so die statistischen Wahrscheinlichkeiten von Wörtern (bzw. Tokens) daraus zu lernen.<br/>
Bekannte Beispiele sind die "GPT" Modelle von OpenAI, die angefangene Texte vervollständigen können.<br/>
<br/>
Ein Reasoning-Modell (wie die "o" Modelle von OpenAI) dagegen soll menschliche Logik abbilden und eigene Schlussfolgerungen ziehen können.<br/>
Da sich logische Argumente in Sprache ausdrücken lassen, sind aktuelle Reasoning-Modelle einfach weiterentwickelte Sprachmodelle.<br/>
<br/>
Der Unterschied ist, dass diese nicht nur eine einfache Text-Fortsetzung generieren und an den/die Nutzer:in zurück geben, wie es ein Sprachmodell macht.<br/>
Stattdessen werden Reasoning-Modelle dazu gebracht, eine Art Zwischentext zu generieren, in dem sie verschiedene logische Schritte betrachten und auch den bereits generierten Text immer wieder überprüfen.<br/>
<br/>
Basierend auf diesem Zwischentext, der jetzt verschiedene Schritte, Argumente und Überprüfungen enthalten sollte, generiert das Modell dann erst die abschließende Antwort, die dem/der Nutzer:in gezeigt wird.</p></span><h2 id="5">Warum die heftige Reaktion?</h2><span><p>
In der Veröffentlichung zu R1 schreibt DeepSeek, dass das Modell in verschiedenen Tests ähnlich gut abschneidet wie das o1 Modell von OpenAI.</p><p>
Angesichts der US-Sanktionen, die den Export der leistungsfähigsten Nvidia-Chips (GPUs) nach China beschränken, wurde das als Hinweis gesehen, dass DeepSeek ein Durchbruch gelungen sein könnte, der das Training von leistungsstarken Modellen sehr viel effizienter macht.</p><p></p><p>
Dazu kommt, dass das R1 Modell auf dem V3 Modell basiert. Zu V3 schreibt DeepSeek, dass das Modell auf "nur" 2.048 Nvidia H800 GPUs trainiert wurde. Bei einem angenommenen Mietpreis von 2$ pro Stunde für eine H800 GPU habe das Training von V3 ca 5,6 Millionen US-Dollar gekostet, was für aktuelle KI-Modelle sehr wenig ist.</p><p></p><p>
Daher entstand der Eindruck, DeepSeek habe für $5,6 Millionen ein Modell entwickelt, das ähnlich leistungsfähig ist wie o1 und dabei mutmaßlich mehrere Größenordnungen weniger kostet.</p><p></p><p>
Diese Annahme ist allerdings nicht ganz richtig, denn der Betrag deckt nur das eigentliche Training des V3 Sprachmodells ab, aber:
<ol>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Schon vor dem Training ist sehr viel Vorbereitungsaufwand notwendig</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Das R1 Modell ist eine Weiterentwicklung von V3, in die vermutlich viel Arbeit geflossen ist</li>
</ol>
Man kann also davon ausgehen, dass die gesamte Entwicklung von R1 deutlich mehr gekostet hat als die genannten $5,6 Millionen, aber wahrscheinlich trotzdem deutlich weniger als die Entwicklung anderer führender KI-Modelle der US-amerikanischen Konkurrenz.</p><p></p><p>
Zum Vergleich: Meta hat das Llama 3 Modell letztes Jahr auf zwei Clustern mit jeweils 24.000 GPUs trainiert und angekündigt, bis Ende 2024 insgesamt 350.000 Nvidia H100 GPUs zu kaufen.</p><p>
Gegenüber diesen Milliarden-Investitionen, die genauso auch OpenAI und andere US-Unternehmen getätigt haben, scheinen die Kosten von DeepSeek extrem gering.</p><p></p><p>
Darauf, dass DeepSeek tatsächlich weniger Kosten für die Entwicklung der Modelle hatte, weisen die Preise hin, die DeepSeek für die Benutzung der eigenen Modelle verlangt - denn die sind sehr viel geringer als die Preise der Konkurrenz.</p><p></p><p>
Wenn es einem chinesischen Startup also gelingen kann, innerhalb kurzer Zeit und zu einem Bruchteil der Kosten ein KI-Modell zu entwickeln, das ähnlich gute Ergebnisse liefert wie die aktuell führenden Modelle, dann wirft das einige Fragen auf:
<ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Ist den chinesischen Forscher:innen ein Durchbruch gelungen, durch den in Zukunft beim Training von KI-Modellen deutlich weniger Rechenleistung nötig sein wird?<br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Können sich die Milliarden-Investitionen in neue Rechenzentren und Supercomputer jemals rechnen, wenn die chinesische Konkurrenz den gleichen Service so viel günstiger anbieten kann?<br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Haben die USA ihre Technologieführerschaft bei KI verloren?</li>
</ul></p></span><h2 id="6">Gab es einen Durchbruch beim Training?</h2><span><p>
Die Forscher:innen von DeepSeek beschreiben mehrere Innovationen, die das Training von V3 effizienter gemacht haben:
<ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Es ist ein "Mixture of Experts" Modell. Das bedeutet, dass immer nur ein kleiner Teil des Modells tatsächlich benutzt wird. Dadurch benötigt es weniger Rechenleistung. Nach diesem Prinzip arbeiten auch schon andere Modelle, z.B. Mixtral und mutmaßlich auch GPT-4, DeepSeek hat es aber noch weiter optimiert.<br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Weitere Verbesserungen sind die sogenannten "multi-head latent attention" und "multi-token prediction". Dadurch wird die Datenverarbeitung bei der Berechnung einer Vorhersage effizienter.<br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Einige Berechnungen werden außerdem mit geringerer Präzision durchgeführt, was ebenfalls dazu führt, dass weniger Rechenleistung benötigt wird.</li>
</ul>
Auch die Weiterentwicklung des V3 Sprachmodells zum R1 Reasoning-Modell hat DeepSeek auf eine relativ effiziente Weise geschafft, denn sie haben stark auf sogenanntes "<a href="https://de.wikipedia.org/wiki/Best%C3%A4rkendes_Lernen" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Reinforcement Learning</a>" gesetzt.</p><p>
Das hat den Vorteil, dass es vollständig automatisch passieren kann, ohne dass das Modell auf menschliche (und damit langsame und teure) Rückmeldungen angewiesen ist.</p><p></p><p>
Beim Reinforcement Learning werden die Antworten des Modells automatisiert geprüft und bewertet, so dass das Modell lernen kann, was eine gute Antwort ist.</p><p></p><p>
Die Kriterien dafür hat DeepSeek sehr einfach gewählt, wodurch sie wiederum auch einfach (und damit ressourcenschonend) überprüfbar waren:
<ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Wurde ein gekennzeichneter Zwischentext generiert?</li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Ist die Antwort richtig? (z.B. bei Rechen- oder Programmieraufgaben ist das für einen Computer relativ leicht zu überprüfen)</li>
</ul>
Beides sind Kriterien, die sich mit einfachen Mitteln, wenig Aufwand und somit kostengünstig und schnell prüfen lassen.</p><p></p><p>
Das ist nicht der eine große Durchbruch, aber mehrere kleine Verbesserungen zusammen genommen können eben auch einen großen Unterschied machen.
                        </p></span><h2 id="7">Rechnen sich die großen KI Investitionen jetzt noch?</h2><span><p>
Erst vor kurzem haben OpenAI und andere im Rahmen eines Projekts namens "Stargate" angekündigt, in den nächsten Jahren viele Milliarden US-Dollar in KI-Infrastruktur zu investieren.</p><p>
Auch der französische Präsident Macron hat erst vor kurzem Investitionen von mehr als 100 Milliarden Euro angekündigt, die EU-Kommission sogar von 200 Milliarden Euro.</p><p></p><p>
Lohnt sich das angesichts der neuen Entwicklungen überhaupt noch?</p><p></p><p>
Diese Frage ist schwierig zu beantworten, weil sie von so vielen Faktoren abhängig ist.
<ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">DeepSeek hat seine Verbesserungen veröffentlicht - wie einfach können sie jetzt von anderen Unternehmen in deren jeweilige KI-Architekturen übernommen werden?<br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Wären die KI-Modelle von DeepSeek noch besser, wenn sie zusätzliche Rechenleistung zur Verfügung gehabt hätten?<br/>
	Könnte also zum Beispiel Meta die Verbesserungen einfach für das nächste Modell ihrer Llama-Reihe übernehmen, es wie bisher auf einem der riesigen GPU-Cluster trainieren, und eine noch viel bessere Leistung bekommen als bisher?<br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Können die Modelle bessere Antworten liefern, wenn sie bei ihren Vorhersagen mehr Rechenleistung zur Verfügung haben? Könnte man die großen Rechenzentren also für den Betrieb der Modelle brauchen, falls sie für das Training nicht mehr nötig sind?<br/>
	Es gibt Hinweise darauf, dass die Rechenleistung nicht nur beim Training eine wichtige Rolle spielt, sondern, dass Modelle auch bessere Vorhersagen machen, wenn man ihnen dabei zusätzliche Rechenleistung gibt (sogenanntes "inference-time compute" oder "test-time compute"). Beispielsweise hat das OpenAIs o3 Modell Ende letzten Jahres beim "arcprize" Wettbewerb gezeigt.<br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Steigt die Nachfrage nach KI, wenn der Preis dafür sinkt? Diese Vermutung hat beispielsweise der CEO von Microsoft, Satya Nadella, mit Bezug auf das <a href="https://de.wikipedia.org/wiki/Jevons-Paradoxon" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">Jevons-Paradoxon</a>, geteilt.</li>
</ul></p></span><h2 id="8">Haben die USA die Technologieführerschaft verloren?</h2><span><p>
Für diese Frage macht die Veröffentlichung von R1, meiner Meinung nach, aus mehreren Gründen keinen großen Unterschied.
<ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">R1 ist zwar ähnlich gut wie OpenAIs o1, aber bei OpenAI ist inzwischen schon der Nachfolger o3 im Einsatz.<br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Die Verbesserungen der Effizienz sind Weiterentwicklungen, aber keine Revolution.<br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">R1 ist auch nicht das erste chinesische Reasoning Modell, z.B. hat Alibaba schon im November 2024 ein Modell namens "QwQ-32B-Preview" veröffentlicht.<br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Und ein Modell zu entwickeln, das ähnlich gut ist, wie eines des aktuellen Marktführers, und noch dazu günstiger, ist zwar eine beachtliche Leistung, aber um selbst die Führung zu beanspruchen reicht das meiner Meinung nach noch nicht aus.</li>
</ul></p><p>
Allerdings hat DeepSeek gezeigt, dass der Vorsprung, den die neuesten Modelle vor Nachahmern haben, im Moment wohl auch von anderen schneller und günstiger aufholbar ist, als bisher angenommen.</p><p></p><p>
Beispielsweise sagt OpenAI, es gäbe Hinweise, dass DeepSeek für das Training der Modelle die Ausgaben von OpenAIs Modellen verwendet hat.</p><p>
Diese Technik nennt sich "Distillation" und ist laut einem Bericht der Financial Times eine weit verbreitete Praxis, um günstig kleinere Modelle zu trainieren, die ähnlich leistungsfähig sind wie deutlich größere, teurere Modelle.</p><p></p><p>
Um Handlungsfähigkeit zu zeigen und den eigenen Technologievorsprung zu betonen, hat OpenAI nur wenige Tage nach der Veröffentlichung von R1 gleich zwei weiterentwickelte Varianten des eigenen Reasoning-Modells o3 zugänglich gemacht.</p><p>
Das eine Modell namens "o3-mini" soll das bisher kostengünstigste sein und ist sogar in der kostenlosen Variante von ChatGPT verfügbar.</p><p>
Die zweite Variante "deep research" setzt auf die größere Version des o3 Modells und verbindet es mit einer Suchfunktion. So soll es selbstständig Antworten auf komplexe Fragen finden können.</p><p></p><p>
Die Nutzung solcher Zusatzfunktionen könnte es schwerer machen, ein Modell mithilfe von Distillation nachzubauen, weil z.B. die Internetsuche im Hintergrund abläuft und man dadurch nicht mehr alle Eingabedaten sehen kann, die ein Modell nutzt, um zu einer Antwort zu kommen.
                        </p></span><h2 id="9">Fazit und Quellen</h2><span><p>
Ich denke, die Leistung des DeepSeek-Teams ist beachtlich und es ist noch nicht genau absehbar, welche Auswirkungen ihre Arbeit haben wird.</p><p></p><p>
Gerade dadurch, dass sie ihre Entwicklungen veröffentlicht haben, im Gegensatz zu vielen anderen KI-Unternehmen, kann deren Einfluss deutlich größer werden.</p><p>
Denn so können die Verbesserungen von allen anderen übernommen, angepasst und noch weiter verbessert werden.</p><p></p><p>
Ob dadurch das Training von KI-Modellen in Zukunft deutlich günstiger wird und die Nachfrage nach Nvidia GPUs einbricht, oder ob durch eventuell sinkende Preise die Nachfrage nach KI noch stärker steigen wird und man somit insgesamt sogar mehr Rechenleistung braucht, kann im Moment noch niemand sicher sagen.</p><p></p><p>
Sicher scheint aktuell fast nichts zu sein, außer dass die KI-Forschung weltweit mit Hochdruck weiter vorangetrieben wird.</p><p></p><p><ul>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">DeepSeek R1 Ankündigung: 📖 <a href="https://api-docs.deepseek.com/news/news250120" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">api-docs.deepseek.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">R1 auf Github: 📖 <a href="https://github.com/deepseek-ai/DeepSeek-R1" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">github.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">R1 ausprobieren: 📖 <a href="https://build.nvidia.com/deepseek-ai/deepseek-r1" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">build.nvidia.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Details zu den technischen Verbesserungen von DeepSeek: 📖 <a href="https://epoch.ai/gradient-updates/how-has-deepseek-improved-the-transformer-architecture" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">epoch.ai</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Analyse der möglichen Auswirkungen: 📖 <a href="https://arcprize.org/blog/r1-zero-r1-results-analysis" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">arcprize.org</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">DeepSeek V3 Ankündigung: 📖 <a href="https://api-docs.deepseek.com/news/news1226" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">api-docs.deepseek.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">V3 auf Github: 📖 <a href="https://github.com/deepseek-ai/DeepSeek-V3" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">github.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Preisliste DeepSeek: 📖 <a href="https://api-docs.deepseek.com/quick_start/pricing" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">api-docs.deepseek.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Preisliste OpenAI: 📖 <a href="https://openai.com/api/pricing/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">openai.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Tweet von Sam Altman zu DeepSeek: 📖 <a href="https://x.com/sama/status/1884066337103962416" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">x.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Reaktion auf DeepSeek am Aktienmarkt: 📖 <a href="https://www.reuters.com/technology/chinas-deepseek-sets-off-ai-market-rout-2025-01-27/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">reuters.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Artikel über das Reasoning Modell von Alibaba: 📖 <a href="https://techcrunch.com/2024/11/27/alibaba-releases-an-open-challenger-to-openais-o1-reasoning-model/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">techcrunch.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Artikel über das Reasoning Modell von Google: 📖 <a href="https://techcrunch.com/2024/12/19/google-releases-its-own-reasoning-ai-model/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">techcrunch.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">OpenAI o3-mini Ankündigung: 📖 <a href="https://openai.com/index/openai-o3-mini/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">openai.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">OpenAI deep research Ankündigung: 📖 <a href="https://openai.com/index/introducing-deep-research/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">openai.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Artikel zu den Distillation-Vorwürfen: 📖 <a href="https://www.ft.com/content/a0dfedd1-5255-4fa9-8ccc-1fe01de87ea6" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">ft.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Artikel zu Projekt Stargate: 📖 <a href="https://www.tagesschau.de/wirtschaft/stargate-ki-trump-100.html" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">tagesschau.de</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Artikel zu Macrons Ankündigung von Investitionen: 📖 <a href="https://www.manager-magazin.de/politik/europa/ki-gipfel-in-paris-frankreich-kuendigt-ki-investitionen-von-mehr-als-100-milliarden-euro-an-a-d589a4fa-8196-4ee8-9304-4896f726ae7a" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">manager-magazin.de</a>, <a href="https://techcrunch.com/2025/02/10/macron-unveils-a-112b-ai-investment-package-as-frances-answer-to-stargate/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">techcrunch.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Ankündigung der EU-Kommission: 📖 <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_25_467" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">ec.europa.eu</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Informationen zum Training von Llama 3: 📖 <a href="https://engineering.fb.com/2024/06/12/data-infrastructure/training-large-language-models-at-scale-meta/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">engineering.fb.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Artikel über die GPU-Pläne von Meta: 📖 <a href="https://www.cnbc.com/2024/01/18/mark-zuckerberg-indicates-meta-is-spending-billions-on-nvidia-ai-chips.html" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">cnbc.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Tweet von Satya Nadella: 📖 <a href="https://x.com/satyanadella/status/1883753899255046301" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">x.com</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">o3 test-time compute arcprize: 📖 <a href="https://arcprize.org/blog/oai-o3-pub-breakthrough" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">arcprize.org</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">QwQ-32B-Preview Ankündigung: 📖 <a href="https://qwenlm.github.io/blog/qwq-32b-preview/" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">qwenlm.github.io</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">Mixtral 8x22B: 📖 <a href="https://mistral.ai/en/news/mixtral-8x22b" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">mistral.ai</a><br/>
	 </li>
<li style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;">GPT-4 Mixture-of-Experts-Gerücht: 📖 <a href="https://x.com/swyx/status/1671272883379908608" style="mso-line-height-rule: exactly;-ms-text-size-adjust: 100%;-webkit-text-size-adjust: 100%;color: #007C89;font-weight: normal;text-decoration: underline;" target="_blank">x.com</a></li>
</ul></p></span>
<p id="bottom-nav-container"><a href="../61">« Vorherige</a><a class="hidden" href="">Nächste »</a></p>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup">
<form action="https://tobiasfraenzel.us7.list-manage.com/subscribe/post?u=6a2f372a93d527ee449b8e785&amp;id=9d690dbb78" class="validate" id="mc-embedded-subscribe-form" method="post" name="mc-embedded-subscribe-form" novalidate="" target="_blank">
<div id="mc_embed_signup_scroll">
<p>Hier abonnieren und keine Ausgabe mehr verpassen:</p>
<!--<div class="indicates-required"><span class="asterisk">*</span> Pflichtfeld</div>-->
<div class="mc-field-group">
<label for="mce-EMAIL">E-Mail Adresse:<!--<span class="asterisk">*</span>--></label>
<input class="required email" id="mce-EMAIL" name="EMAIL" type="email" value=""/>
</div>
<!--<div class="mc-field-group">
                      <label for="mce-FNAME">Name</label>
                          <input type="text" value="" name="FNAME" class="" id="mce-FNAME">
                  </div>-->
<div class="clear" id="mce-responses">
<div class="response" id="mce-error-response" style="display:none"></div>
<div class="response" id="mce-success-response" style="display:none"></div>
</div> <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
<div aria-hidden="true" style="position: absolute; left: -5000px;"><input name="b_6a2f372a93d527ee449b8e785_9d690dbb78" tabindex="-1" type="text" value=""/></div>
<div class="clear"><input class="button" id="mc-embedded-subscribe" name="subscribe" type="submit" value="Anmelden"/></div>
</div>
</form>
</div>
</div>
</body>
<!-- Matomo -->
<script type="text/javascript">
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
      var u="//tobiasfraenzel.de/misc/piwik/";
      _paq.push(['setTrackerUrl', u+'matomo.php']);
      _paq.push(['setSiteId', '1']);
      var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
      g.type='text/javascript'; g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
    })();
  </script>
<!-- End Matomo Code -->
</html>
